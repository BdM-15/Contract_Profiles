{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://www.kdnuggets.com/introduction-ray-swiss-army-knife-distributed-computing\n",
        "\n",
        "Today, applications handle large datasets and complex tasks. To meet these demands, many frameworks for distributed computing have been developed to speed up processes and reduce delays. One such popular framework is Ray. Ray is a flexible tool designed for cloud-based distributed computing and for building scalable machine learning systems. This article explores Ray, its key features, and its applications.\n",
        "\n",
        "ONLY WORKS IN 'base (Python 3.11.7)' miniconda \"kernel\" on my computer.  Libraries aren't recognized in 'base (Python) 3.12.17' anaconda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray is an open-source tool for distributed computing. It helps run tasks on multiple computers. Ray handles large datasets and complex operations. It makes scaling applications easier. Key features include an easy API, scalability, fault tolerance, and support for tasks like machine learning. Ray has libraries like Ray Core, Ray Data, Ray Train, Ray Tune, Ray Serve, and Ray RLlib. Each helps with specific tasks like data processing and model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use Cases of Ray\n",
        " \n",
        "Ray is a tool that can be used in many different scenarios.\n",
        "\n",
        "1. Distributed Machine Learning: Ray speeds up machine learning model training across multiple computers. It is great for large datasets and complex models, especially in deep learning and reinforcement learning.\n",
        "2. Hyperparameter Tuning: Ray Tune helps optimize machine learning models by testing different combinations of parameters. It speeds up the process of finding the best settings.\n",
        "3. Model Serving: Ray Serve deploys machine learning models for real-time predictions. It scales dynamically to handle different loads with low latency.\n",
        "4. Reinforcement Learning: Ray RLlib trains reinforcement learning models. It supports multiple algorithms and scales across machines for large, complex models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray Core\n",
        "Ray Core is the base of the Ray framework. It helps build distributed applications. It also handles task scheduling and object management. Ray Core makes sure tasks run even if something fails. You can use it to run functions on many machines at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "# Initialize Ray\n",
        "ray.init()\n",
        "\n",
        "# Define a simple function to be parallelized\n",
        "@ray.remote\n",
        "def my_function(x):\n",
        "    return x * x\n",
        "\n",
        "# Run the function in parallel\n",
        "futures = [my_function.remote(i) for i in range(10)]\n",
        "results = ray.get(futures)\n",
        "\n",
        "print(results)  # Output: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
        "\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray Data\n",
        "Ray Data provides abstractions to distribute data processing tasks, such as reading and preprocessing large datasets. It can scale tasks like data transformation, cleaning, and aggregation across multiple nodes.\n",
        "\n",
        "Install Ray Data using the following command: pip install -U 'ray[data]'\n",
        "\n",
        "Example: Scaling Data Processing with Ray Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ray.data import read_csv\n",
        "\n",
        "# Initialize Ray\n",
        "ray.init()\n",
        "\n",
        "# Load a large dataset\n",
        "dataset = read_csv(\"large_dataset.csv\")\n",
        "\n",
        "# Apply transformation (filtering, mapping)\n",
        "filtered = dataset.filter(lambda row: row[\"value\"] > 10)\n",
        "aggregated = filtered.groupby(\"category\").sum(\"value\")\n",
        "\n",
        "# Show processed results\n",
        "print(aggregated.take(10))\n",
        "\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray Train\n",
        "Ray Train helps train machine learning models across many machines. It makes training faster by spreading the work over multiple nodes. This is useful for large datasets and complex models.\n",
        "\n",
        "Install Ray Train using the following command: pip install -U \"ray[train]\"\n",
        "\n",
        "Example: Scaling Machine Learning Training with Ray Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ray.train import Trainer\n",
        "from ray.train.sklearn import SklearnTrainer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Initialize Ray\n",
        "ray.init()\n",
        "\n",
        "# Load a sample dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Define training function\n",
        "def train_model():\n",
        "    model = RandomForestClassifier(n_estimators=100)\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "# Use SklearnTrainer to scale training\n",
        "trainer = SklearnTrainer(train_func=train_model)\n",
        "trainer.fit()\n",
        "\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray Tune\n",
        "Ray Tune is a tool for hyperparameter tuning. It can test many combinations at the same time. You can use methods like grid search or random search. It also supports advanced methods like Bayesian optimization. Ray Tune helps optimize models quickly and efficiently.\n",
        "\n",
        "Install Ray Tune using the following command: pip install \"ray[tune]\"\n",
        "\n",
        "Example: Scaling Hyperparameter Tuning with Ray Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "\n",
        "# Define training function with hyperparameters\n",
        "def train_model(config):\n",
        "    learning_rate = config[\"learning_rate\"]\n",
        "    for step in range(100):\n",
        "        loss = (learning_rate * step) ** 0.5\n",
        "        tune.report(loss=loss)\n",
        "\n",
        "# Initialize Ray\n",
        "ray.init()\n",
        "\n",
        "# Run hyperparameter tuning with Ray Tune\n",
        "analysis = tune.run(\n",
        "    train_model,\n",
        "    config={\n",
        "        \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n",
        "    },\n",
        "    scheduler=ASHAScheduler(metric=\"loss\", mode=\"min\"),\n",
        ")\n",
        "\n",
        "print(\"Best config: \", analysis.best_config)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray Serve\n",
        "Ray Serve is a tool for scaling model serving. It helps serve machine learning models in a distributed manner with dynamic scaling, load balancing, and low latency.\n",
        "\n",
        "Install Ray Tune using the following command: pip install \"ray[serve]\"\n",
        "\n",
        "Example: Scaling Model Serving with Ray Serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ray import serve\n",
        "import requests\n",
        "\n",
        "# Initialize Ray Serve\n",
        "serve.start()\n",
        "\n",
        "# Define a model deployment\n",
        "@serve.deployment\n",
        "def model(request):\n",
        "    return {\"message\": \"Hello, Ray Serve!\"}\n",
        "\n",
        "# Deploy the model\n",
        "model.deploy()\n",
        "\n",
        "# Send a request to the model\n",
        "response = requests.get(\"http://127.0.0.1:8000/model\")\n",
        "print(response.json())\n",
        "\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray RLlib\n",
        "Ray RLlib helps train reinforcement learning models on multiple machines. It supports different algorithms, like Proximal Policy Optimization (PPO) and Deep Q-Network (DQN). These algorithms help teach models to make decisions based on rewards and actions.\n",
        "\n",
        "Install Ray Tune using the following command: pip install \"ray[rllib]\"\n",
        "\n",
        "Example: Scaling Reinforcement Learning with Ray RLlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ray.rllib.algorithms.ppo import PPO\n",
        "\n",
        "# Initialize Ray\n",
        "ray.init()\n",
        "\n",
        "# Define configuration for RL agent\n",
        "config = {\n",
        "    \"env\": \"CartPole-v1\",\n",
        "    \"framework\": \"torch\",  # or \"tf\"\n",
        "    \"num_workers\": 4,  # Number of parallel workers\n",
        "}\n",
        "\n",
        "# Train a PPO agent\n",
        "trainer = PPO(config=config)\n",
        "for _ in range(10):\n",
        "    result = trainer.train()\n",
        "    print(f\"Episode reward: {result['episode_reward_mean']}\")\n",
        "\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(r'C:\\PyProjects\\OSBP Insights\\data\\raw\\cleansed\\data_source.csv')\n",
        "# obsp_forecast_df = pd.read_csv(r'C:\\PyProjects\\OSBP Insights\\references\\forecast_listing\\osbp_dashboard_forecast.csv')\n",
        "# amc_forecast_df = pd.read_csv(r'C:\\PyProjects\\OSBP Insights\\references\\forecast_listing\\amc_forecast_listing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29329 entries, 0 to 29328\n",
            "Data columns (total 56 columns):\n",
            " #   Column                                   Non-Null Count  Dtype  \n",
            "---  ------                                   --------------  -----  \n",
            " 0   Contract No                              29329 non-null  object \n",
            " 1   Order No                                 29329 non-null  object \n",
            " 2   Modification No                          29329 non-null  object \n",
            " 3   Award Date                               29329 non-null  object \n",
            " 4   Fiscal Year                              29329 non-null  int64  \n",
            " 5   Command                                  29329 non-null  object \n",
            " 6   Sub Command                              29329 non-null  object \n",
            " 7   Organization                             29329 non-null  object \n",
            " 8   Office                                   29329 non-null  object \n",
            " 9   Office Id                                29329 non-null  object \n",
            " 10  Army Hierarchy                           29024 non-null  object \n",
            " 11  PEO/Command                              29024 non-null  object \n",
            " 12  PM/Directorate                           29024 non-null  object \n",
            " 13  VCE-PCF Project/Program Title            3950 non-null   object \n",
            " 14  Funding Office Id                        29329 non-null  object \n",
            " 15  Funding Office Name                      29329 non-null  object \n",
            " 16  Awardee                                  29328 non-null  object \n",
            " 17  Entity Unique Id                         29326 non-null  object \n",
            " 18  Small Business Eligible Actions          29329 non-null  int64  \n",
            " 19  Small Business Eligible Dollars          29329 non-null  float64\n",
            " 20  Size Status                              29329 non-null  object \n",
            " 21  SB Dollars                               29329 non-null  float64\n",
            " 22  Small Business  %                        29329 non-null  object \n",
            " 23  SDB Concern Actions                      29329 non-null  int64  \n",
            " 24  SDB Concern Dollars                      29329 non-null  float64\n",
            " 25  SDB Concern %                            29329 non-null  object \n",
            " 26  Service Disabled Veterans Actions        29329 non-null  int64  \n",
            " 27  Service Disabled Veterans Dollars        29329 non-null  float64\n",
            " 28  SVC Disabled Veteran %                   29329 non-null  object \n",
            " 29  Women Owned Actions                      29329 non-null  int64  \n",
            " 30  Women Owned Dollars                      29329 non-null  float64\n",
            " 31  Women Owned %                            29329 non-null  object \n",
            " 32  HUB Zone Actions                         29329 non-null  int64  \n",
            " 33  HUB Zone Dollars                         29329 non-null  float64\n",
            " 34  HUB Zone %                               29329 non-null  object \n",
            " 35  OMB Level 1                              29329 non-null  object \n",
            " 36  OMB Level 2                              29329 non-null  object \n",
            " 37  PSC                                      29329 non-null  object \n",
            " 38  PSC Description                          29312 non-null  object \n",
            " 39  NAICS                                    29325 non-null  float64\n",
            " 40  NAICS Description                        29325 non-null  object \n",
            " 41  Congressional District - Vendor          28239 non-null  float64\n",
            " 42  Congressional District - POP             24150 non-null  float64\n",
            " 43  Subcontracting Plan Description          24933 non-null  object \n",
            " 44  National Interest Description            23149 non-null  object \n",
            " 45  SBIR/STTR Type                           53 non-null     object \n",
            " 46  Bundling                                 29185 non-null  object \n",
            " 47  Contract Expiration Flag                 29329 non-null  object \n",
            " 48  Expiration                               25298 non-null  object \n",
            " 49  Months Remaining                         25298 non-null  float64\n",
            " 50  Awarding PCO (CWS)                       28733 non-null  object \n",
            " 51  Type Set Aside Description               29329 non-null  object \n",
            " 52  Requirements Description                 29329 non-null  object \n",
            " 53  12C Reason for Modification Description  21632 non-null  object \n",
            " 54  Contract Action Type                     29329 non-null  object \n",
            " 55  Instrument Type                          29329 non-null  object \n",
            "dtypes: float64(10), int64(6), object(40)\n",
            "memory usage: 12.5+ MB\n"
          ]
        }
      ],
      "source": [
        "# Filter acc_ri_awards_df to not inlcude any rows with a value of 'MODFICATION\", \"SATOC\", AND \"MATOC\" in the 'Contract Action Type' column\n",
        "df.info()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
